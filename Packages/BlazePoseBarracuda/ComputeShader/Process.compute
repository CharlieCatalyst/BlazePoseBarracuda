#pragma kernel LetterBoxImage
#pragma kernel PoseRegionUpdate
#pragma kernel CropImage
#pragma kernel PostProcess

#define PI 3.14159265359

#include "PoseRegion.cginc"
#include "LowPassFilter.cginc"
#include "Misc.cginc"
#include "ColorSpace.cginc"
#include "Packages/jp.ikep.mediapipe.posedetection/ComputeShader/Common.cginc"


// Kernel 0
uint _letterboxWidth;
float2 _spadScale;
sampler2D _letterboxInput;
RWTexture2D<float4> _letterboxTexture;

// Generate letter-box image texture.
[numthreads(8, 8, 1)]
void LetterBoxImage(uint2 id : SV_DispatchThreadID)
{
    if (any(id > _letterboxWidth)) return;

    // UV coordinates
    float2 uv = (id + 0.5) / _letterboxWidth;

    // Scaling
    uv = (uv - 0.5) * _spadScale + 0.5;

    // UV gradients
    float2 duv_dx = float2(+1.0 / _letterboxWidth * _spadScale.x, 0);
    float2 duv_dy = float2(0, -1.0 / _letterboxWidth * _spadScale.y);

    // Texture sample
    float3 rgb = tex2Dgrad(_letterboxInput, uv, duv_dx, duv_dy).rgb;

    // Bounding
    rgb *= all(uv > 0) && all (uv < 1);

    // Comvert sRGB color (= Liner color space) because Compute Shader texture output is not converted.
    #if !UNITY_COLORSPACE_GAMMA
    rgb = LinearToSRGB(rgb);
    #endif

    _letterboxTexture[id] = float4(rgb, 1);
}


// Kernel 1
float _deltaTime;
uint _upperBodyOnly;
StructuredBuffer<PoseDetection> _poseDetections;
ByteAddressBuffer _poseDetectionCount;
RWStructuredBuffer<PoseRegion> _poseRegions;

// Update PoseRegion.
[numthreads(1, 1, 1)]
void PoseRegionUpdate(uint id : SV_DispatchThreadID)
{
    uint count = _poseDetectionCount.Load(0);
    if (count <= 0) return;

    // Get pose detection result by neural network model.
    const PoseDetection pd = _poseDetections[0];

    float2 hip = pd.keyPoints[0];
    float2 shoulder = pd.keyPoints[2];

    // Rotation center point
    float2 center = _upperBodyOnly ? shoulder : hip;
    float2 roi = _upperBodyOnly ? pd.keyPoints[3] : pd.keyPoints[1];

    // Image crop size
    float sizeX = abs(roi.x - center.x);
    float sizeY = abs(roi.y - center.y);
    float size = max(sizeX, sizeY) * 3.0;

    // Pose angle
    float target = PI * 0.5;
    const float2 up = shoulder - hip;
    float angle = atan2(-up.y, up.x) - target;

    center.y = 1 - center.y;
    PoseRegion pr = _poseRegions[0];

    // Low pass filter parameters and input vector
    const float3 lpf_params = float3(2, 1.5f, _deltaTime);
    // This frame region
    const float4 box = float4(center, size, angle);
    // Calculate PoseRegion delta with low pass filter for decrease jitter.
    pr.dBox = lpf_Step_dx(box, pr.box, pr.dBox, lpf_params);
    // Calculate PoseRegion with low pass filter for decrease jitter.
    pr.box = lpf_Step_x(box, pr.box, pr.dBox, lpf_params);

    // Region crop matrix update
    float4x4 m1 = makeTranslationMatrix(pr.box.xy - pr.box.z / 2);
    float4x4 m2 = makeScalingMatrix(pr.box.z);
    float4x4 m3 = makeTranslationMatrix(0.5);
    float4x4 m4 = makeRotationMatrix(pr.box.w);
    float4x4 m5 = makeTranslationMatrix(-0.5);
    pr.cropMatrix = mul(mul(mul(mul(m1, m2), m3), m4), m5);

    _poseRegions[0] = pr;
}


// Kernel 2
#define CROP_IMAGE_SIZE 256

sampler2D _inputTexture;
StructuredBuffer<PoseRegion> _cropRegion;
RWTexture2D<float4> _cropedTexture;

// Crop image from PoseRegion.
[numthreads(8, 8, 1)]
void CropImage(uint2 id : SV_DispatchThreadID)
{
    float4x4 xform = _cropRegion[0].cropMatrix;

    // UV coordinates
    float2 uv = (id + 0.5) / CROP_IMAGE_SIZE;
    uv = mul(xform, float4(uv, 0, 1)).xy;

    // De-letterboxing
    uv = (uv - 0.5) * _spadScale + 0.5;

    // UV gradients
    float2 duv_dx = mul(xform, float4(1.0 / CROP_IMAGE_SIZE, 0, 0, 0)).xy;
    float2 duv_dy = mul(xform, float4(0, -1.0 / CROP_IMAGE_SIZE, 0, 0)).xy;

    // Texture sample
    float3 rgb = tex2Dgrad(_inputTexture, uv, duv_dx, duv_dy).rgb;

    // Comvert sRGB color (= Liner color space) because Compute Shader texture output is not converted.
    #if !UNITY_COLORSPACE_GAMMA
    rgb = LinearToSRGB(rgb);
    #endif
    
    // Set pixel value.
    _cropedTexture[id] = float4(rgb, 1);
}


// Kernel 3

#define LPF_WINDOW_MAX_COUNT 5

uint _isWorldProcess;
uint _keypointCount;
float _postDeltatime;
float _velocity_scale;
uint _rvfWindowCount;

StructuredBuffer<float4> _postInput;
StructuredBuffer<PoseRegion> _postRegion;

RWTexture2D<float4> _postRvfWindow;
RWStructuredBuffer<float3> _postLastValueScale;
RWStructuredBuffer<float4> _postOutput;

// Map pose landmark to cordinates on the original input image.
[numthreads(33 + 1, 1, 1)]
void PostProcess(uint id : SV_DispatchThreadID)
{
    if(id > _keypointCount) return;

    if(id == _keypointCount){
        // Set human exist score in last index.
        _postOutput[id] = _postInput[_keypointCount];
    }
    else{
        // Process for normalized landmark
        PoseRegion region = _postRegion[0];
        // Visiblity of pose landmark
        float score = _postInput[id].w;
        // Pose landmark
        float3 x = _postInput[id].xyz;
        // Pose landmark on previous frame
        float3 p_x = _postOutput[id].xyz;
        // previous value scale for relative velocity filter
        float3 p_value_scale = _postLastValueScale[id];

        if(_isWorldProcess){
            x = mul(makeRotationMatrix(region.box.w), float4(x, 1)).xyz;
        }
        else{
            // Map to cordinates of letter-box image from croped image.
            x = mul(region.cropMatrix, float4(x, 1)).xyz;
            // Map to cordinates of original input image from letter-box image.
            x.xy = (x.xy - 0.5) * _spadScale + 0.5;
        }

        // Apply relative velocity filter
        // reference: 
        // https://github.com/asus4/tf-lite-unity-sample/blob/26e49bf4a45a550f84f12635a97102a3e207009e/Packages/com.github.asus4.mediapipe/Runtime/RelativeVelocityFilter.cs
        float min_x = _postInput[0].x;
        float max_x = _postInput[0].x;
        float min_y = _postInput[0].y;
        float max_y = _postInput[0].y;
        for(int k = 0; k<33; k++){
            if(min_x > _postInput[k].x) min_x = _postInput[k].x;
            if(max_x < _postInput[k].x) max_x = _postInput[k].x;
            if(min_y > _postInput[k].y) min_y = _postInput[k].y;
            if(max_y < _postInput[k].y) max_y = _postInput[k].y;
        }

        float2 size = float2(max_x - min_x, max_y - min_y);
        float3 value_scale = 1.0f / ((size.x + size.y) / 2);
        int window_size = min(_rvfWindowCount, LPF_WINDOW_MAX_COUNT);

        if(window_size > 0){
            float3 distance = x * value_scale - p_x * p_value_scale;
            float3 distance_sum = distance;
            float duration_sum = _postDeltatime;
            float duration_max = (1 + window_size) * _postDeltatime;
            
            for(int i = 0; i < window_size; i++){
                float3 p_distance = _postRvfWindow[uint2(i, id)].xyz;
                float p_duration = _postRvfWindow[uint2(i, id)].w;
                if(duration_sum + p_duration > duration_max) break;
                distance_sum += p_distance;
                duration_sum +=p_duration;
            }

            float3 velocity = distance_sum / duration_sum;
            float3 alpha = 1.0 - 1.0 / (1.0 + _velocity_scale * abs(velocity));
            x = lerp(p_x, x, alpha);

            // window enqueue & dequeue for next frame
            if(window_size == LPF_WINDOW_MAX_COUNT){
                for(int j = 0; j < window_size - 1; j++){
                    _postRvfWindow[uint2(j, id)] = _postRvfWindow[uint2(j+1, id)];
                }
                _postRvfWindow[uint2(window_size - 1, id)] = float4(distance, _postDeltatime);
            }
            else{
                _postRvfWindow[uint2(window_size, id)] = float4(distance, _postDeltatime);
            }
        }

        _postOutput[id] = float4(x, score);
        _postLastValueScale[id] = value_scale;
    }
}
